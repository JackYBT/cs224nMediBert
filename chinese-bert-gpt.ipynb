{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import fire\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chinese-gpt in /home/ubuntu/.local/lib/python3.8/site-packages (0.1.3)\n",
      "Requirement already satisfied: pytorch-pretrained-bert in /home/ubuntu/.local/lib/python3.8/site-packages (from chinese-gpt) (0.6.2)\n",
      "Requirement already satisfied: allennlp in /home/ubuntu/.local/lib/python3.8/site-packages (from chinese-gpt) (2.10.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.8/site-packages (from chinese-gpt) (4.65.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert->chinese-gpt) (2.28.2)\n",
      "Requirement already satisfied: regex in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert->chinese-gpt) (2022.10.31)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert->chinese-gpt) (1.24.2)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert->chinese-gpt) (1.12.1)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch-pretrained-bert->chinese-gpt) (1.26.90)\n",
      "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.13.1)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (3.20.3)\n",
      "Requirement already satisfied: spacy<3.4,>=2.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (3.3.2)\n",
      "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.19.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (1.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.16 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.12.1)\n",
      "Requirement already satisfied: filelock<3.8,>=3.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (3.7.1)\n",
      "Requirement already satisfied: termcolor==1.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (1.1.0)\n",
      "Requirement already satisfied: nltk>=3.6.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (3.8.1)\n",
      "Requirement already satisfied: h5py>=3.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (3.8.0)\n",
      "Requirement already satisfied: wandb<0.13.0,>=0.10.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.12.21)\n",
      "Requirement already satisfied: transformers<4.21,>=4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (4.20.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.1.97)\n",
      "Requirement already satisfied: cached-path<1.2.0,>=1.1.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (1.1.6)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.3.6)\n",
      "Requirement already satisfied: more-itertools>=8.12.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (9.1.0)\n",
      "Requirement already satisfied: scipy>=1.7.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (1.10.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.7.0)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.0.53)\n",
      "Requirement already satisfied: traitlets>5.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (5.9.0)\n",
      "Requirement already satisfied: lmdb>=1.2.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (1.4.0)\n",
      "Requirement already satisfied: pytest>=6.2.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (7.2.2)\n",
      "Requirement already satisfied: fairscale==0.4.6 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (0.4.6)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (2.6)\n",
      "Requirement already satisfied: base58>=2.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from allennlp->chinese-gpt) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->pytorch-pretrained-bert->chinese-gpt) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert->chinese-gpt) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch-pretrained-bert->chinese-gpt) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert->chinese-gpt) (1.26.14)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.8/site-packages (from torch>=0.4.1->pytorch-pretrained-bert->chinese-gpt) (4.5.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.90 in /home/ubuntu/.local/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->chinese-gpt) (1.29.90)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->chinese-gpt) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->chinese-gpt) (0.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from torchvision<0.14.0,>=0.8.1->allennlp->chinese-gpt) (9.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (6.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (2.4.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (8.0.17)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (1.0.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (2.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (45.2.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from spacy<3.4,>=2.1.0->allennlp->chinese-gpt) (0.7.9)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.1->allennlp->chinese-gpt) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.1->allennlp->chinese-gpt) (3.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.0.16->allennlp->chinese-gpt) (5.3.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk>=3.6.5->allennlp->chinese-gpt) (7.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (2.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (1.16.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (1.0.11)\n",
      "Requirement already satisfied: setproctitle in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (1.3.2)\n",
      "Requirement already satisfied: pathtools in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (1.14.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (3.1.31)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (5.9.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from transformers<4.21,>=4.1->allennlp->chinese-gpt) (0.12.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (2.7.0)\n",
      "Requirement already satisfied: rich<13.0,>=12.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (12.6.0)\n",
      "Requirement already satisfied: tomli>=1.0.0; python_version < \"3.11\" in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=6.2.5->allennlp->chinese-gpt) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=6.2.5->allennlp->chinese-gpt) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=6.2.5->allennlp->chinese-gpt) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8; python_version < \"3.11\" in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=6.2.5->allennlp->chinese-gpt) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from pytest>=6.2.5->allennlp->chinese-gpt) (19.3.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.90->boto3->pytorch-pretrained-bert->chinese-gpt) (2.8.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (4.0.10)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (2.11.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (2.4.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (2.3.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (2.16.2)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (2.14.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp->chinese-gpt) (5.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (1.58.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (1.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/ubuntu/.local/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (4.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp->chinese-gpt) (0.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/chinese_gpt/gpt_modeling.py:26: UserWarning: Try to install apex to improve your performance!\n",
      "  warnings.warn(\"Try to install apex to improve your performance!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in /home/ubuntu/.local/lib/python3.8/site-packages (0.6.2)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch_pretrained_bert) (4.65.0)\n",
      "Requirement already satisfied: boto3 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch_pretrained_bert) (1.26.90)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch_pretrained_bert) (1.12.1)\n",
      "Requirement already satisfied: regex in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch_pretrained_bert) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.local/lib/python3.8/site-packages (from pytorch_pretrained_bert) (2.28.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.90 in /home/ubuntu/.local/lib/python3.8/site-packages (from boto3->pytorch_pretrained_bert) (1.29.90)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.8/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.8/site-packages (from requests->pytorch_pretrained_bert) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from requests->pytorch_pretrained_bert) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.90->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.90->boto3->pytorch_pretrained_bert) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# imports chinese gpt\n",
    "!pip install chinese-gpt\n",
    "from chinese_gpt import TransformerEncoder, TransformerDecoderLM\n",
    "\n",
    "# uses bert chinese wordpiece tokenization\n",
    "!pip install pytorch_pretrained_bert\n",
    "from pytorch_pretrained_bert import OpenAIAdam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, *data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return tuple(data[index] for data in self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    pad_id = 0\n",
    "    input_ids = []\n",
    "    output_ids = []\n",
    "    input_mask = []\n",
    "    output_mask =[]\n",
    "\n",
    "    btc_size = len(batch)\n",
    "    max_input_len = 0  # 该batch中最长的input，用于该batch的数据对齐\n",
    "    max_output_len = 0\n",
    "\n",
    "    # 计算该batch中input的最大长度\n",
    "    for btc_idx in range(btc_size):\n",
    "        if max_input_len < len(batch[btc_idx][0]):\n",
    "            max_input_len = len(batch[btc_idx][0])\n",
    "        if max_output_len < len(batch[btc_idx][1]):\n",
    "            max_output_len = len(batch[btc_idx][1])\n",
    "    # 使用pad_id对小于max_input_len的input_id进行补全\n",
    "\n",
    "    for btc_idx in range(btc_size):\n",
    "        input_len = len(batch[btc_idx][0])\n",
    "        input_ids.append(batch[btc_idx][0])\n",
    "        input_ids[btc_idx].extend([pad_id] * (max_input_len - input_len))\n",
    "\n",
    "        output_len = len(batch[btc_idx][1])\n",
    "        output_ids.append(batch[btc_idx][1])\n",
    "        output_ids[btc_idx].extend([pad_id] * (max_output_len - output_len))\n",
    "\n",
    "        input_mask.append([1] * input_len + [pad_id] * (max_input_len - input_len))\n",
    "        output_mask.append([1] * output_len + [pad_id] * (max_output_len - output_len))\n",
    "    return tuple((torch.tensor(input_ids, dtype=torch.long), torch.tensor(output_ids, dtype=torch.long), torch.tensor(input_mask, dtype=torch.long), torch.tensor(output_mask, dtype=torch.long)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BertGPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder()\n",
    "\n",
    "        # for p in self.parameters():\n",
    "        #     p.requires_grad=False\n",
    "\n",
    "        self.decoder = TransformerDecoderLM()\n",
    "\n",
    "    def forward(self, encoder_input, mask_encoder_input, decoder_input, mask_decoder_input):\n",
    "        _, past = self.encoder(encoder_input, mask_encoder_input)\n",
    "\n",
    "        mask = torch.cat([mask_encoder_input, mask_decoder_input], dim=1)\n",
    "        logits, _ = self.decoder(decoder_input, mask, past=past, past_length=0)\n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(\n",
    "    epochs=10,\n",
    "    num_gradients_accumulation=4,\n",
    "    batch_size=8,\n",
    "    gpu_id=0,\n",
    "    lr=1e-5,\n",
    "    load_dir='decoder_model',\n",
    "    decoder_model='original_pretrained_model_for_bertGPT.pth'\n",
    "    ):\n",
    "    # make sure your model is on GPU\n",
    "    device = torch.device(f\"cuda:{gpu_id}\")\n",
    "\n",
    "    #------------------------LOAD MODEL-----------------\n",
    "    print('load the model....')\n",
    "    model = BertGPT()\n",
    "\n",
    "    # model.load_state_dict(torch.load(decoder_model))\n",
    "\n",
    "    model = nn.DataParallel(model, device_ids = [0,1,2])\n",
    "    model = model.to(device)\n",
    "    print('load success')\n",
    "    #------------------------END LOAD MODEL--------------\n",
    "\n",
    "\n",
    "    #------------------------LOAD TRAIN DATA------------------\n",
    "    train_data = torch.load(\"train_data.pth\")\n",
    "    train_dataset = MyDataset(*train_data)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=batch_size, num_workers=2, collate_fn=collate_fn)\n",
    "    val_data = torch.load(\"validate_data.pth\")\n",
    "    val_dataset = MyDataset(*val_data)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, shuffle=True, batch_size=batch_size, num_workers=2, collate_fn=collate_fn)\n",
    "    #------------------------END LOAD TRAIN DATA--------------\n",
    "    \n",
    "\n",
    "    #------------------------SET OPTIMIZER-------------------\n",
    "    num_train_optimization_steps = len(train_dataset) * epochs // batch_size // num_gradients_accumulation\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay) and p.requires_grad], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay) and p.requires_grad], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    print('train')\n",
    "    print(len(optimizer_grouped_parameters[0]['params']))\n",
    "\n",
    "    optimizer = OpenAIAdam(optimizer_grouped_parameters,\n",
    "                        lr=lr,\n",
    "                        warmup=0.01,\n",
    "                        max_grad_norm=1.0,\n",
    "                        weight_decay=0.01,\n",
    "                        t_total=num_train_optimization_steps)\n",
    "    #------------------------END SET OPTIMIZER--------------\n",
    "\n",
    "\n",
    "    #------------------------START TRAINING-------------------\n",
    "    update_count = 0\n",
    "\n",
    "    start = time.time()\n",
    "    print('start training....')\n",
    "    for epoch in range(epochs):\n",
    "        #------------------------training------------------------\n",
    "        model.train()\n",
    "        losses = 0\n",
    "        times = 0\n",
    "        for batch in tqdm(train_dataloader, desc='dirs'):\n",
    "            batch = [item.to(device) for item in batch]\n",
    "\n",
    "            encoder_input, decoder_input, mask_encoder_input, mask_decoder_input = batch\n",
    "\n",
    "            logits = model(encoder_input, mask_encoder_input, decoder_input, mask_decoder_input)\n",
    "  \n",
    "            out = logits[:, :-1].contiguous()\n",
    "            target = decoder_input[:, 1:].contiguous()\n",
    "            target_mask = mask_decoder_input[:, 1:].contiguous()\n",
    "            loss = util.sequence_cross_entropy_with_logits(out, target, target_mask, average=\"token\")\n",
    "            loss.backward()\n",
    "\n",
    "            losses += loss.item()\n",
    "            times += 1\n",
    "            \n",
    "            update_count += 1\n",
    "\n",
    "            ## What does this mean?? why only calling optimizer after a certain threshold \n",
    "\n",
    "            if update_count % num_gradients_accumulation == num_gradients_accumulation - 1:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        end = time.time()\n",
    "        print('-'*20 + f'epoch {epoch}' + '-'*20)\n",
    "        print(f'time: {(end - start)}')\n",
    "        print(f'loss: {losses / times}')\n",
    "        start = end\n",
    "\n",
    "        #------------------------validate------------------------\n",
    "        model.eval()\n",
    "\n",
    "        perplexity = 0\n",
    "        batch_count = 0\n",
    "        print('start calculate the perplexity....')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader):\n",
    "                batch = [item.to(device) for item in batch]\n",
    "                encoder_input, decoder_input, mask_encoder_input, mask_decoder_input = batch\n",
    "\n",
    "                logits = model(encoder_input, mask_encoder_input, decoder_input, mask_decoder_input)\n",
    "                \n",
    "                out = logits[:, :-1].contiguous()\n",
    "                target = decoder_input[:, 1:].contiguous()\n",
    "                target_mask = mask_decoder_input[:, 1:].contiguous()\n",
    "\n",
    "                loss = util.sequence_cross_entropy_with_logits(out, target, target_mask, average=\"token\")\n",
    "                perplexity += np.exp(loss.item())\n",
    "                batch_count += 1\n",
    "\n",
    "        print(f'validate perplexity: {perplexity / batch_count}')\n",
    "\n",
    "        torch.save(model.module.state_dict(), os.path.join(os.path.abspath('.'), load_dir, str(epoch) + \"decoder.pth\"))\n",
    "\n",
    "    #------------------------END TRAINING-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA A10G with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA A10G GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Invalid device id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fire\u001b[39m.\u001b[39;49mFire(train_model)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fire/core.py:141\u001b[0m, in \u001b[0;36mFire\u001b[0;34m(component, command, name, serialize)\u001b[0m\n\u001b[1;32m    138\u001b[0m   context\u001b[39m.\u001b[39mupdate(caller_globals)\n\u001b[1;32m    139\u001b[0m   context\u001b[39m.\u001b[39mupdate(caller_locals)\n\u001b[0;32m--> 141\u001b[0m component_trace \u001b[39m=\u001b[39m _Fire(component, args, parsed_flag_args, context, name)\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m component_trace\u001b[39m.\u001b[39mHasError():\n\u001b[1;32m    144\u001b[0m   _DisplayError(component_trace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fire/core.py:475\u001b[0m, in \u001b[0;36m_Fire\u001b[0;34m(component, args, parsed_flag_args, context, name)\u001b[0m\n\u001b[1;32m    472\u001b[0m is_class \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39misclass(component)\n\u001b[1;32m    474\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m   component, remaining_args \u001b[39m=\u001b[39m _CallAndUpdateTrace(\n\u001b[1;32m    476\u001b[0m       component,\n\u001b[1;32m    477\u001b[0m       remaining_args,\n\u001b[1;32m    478\u001b[0m       component_trace,\n\u001b[1;32m    479\u001b[0m       treatment\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m is_class \u001b[39melse\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mroutine\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    480\u001b[0m       target\u001b[39m=\u001b[39;49mcomponent\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m    481\u001b[0m   handled \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    482\u001b[0m \u001b[39mexcept\u001b[39;00m FireError \u001b[39mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fire/core.py:691\u001b[0m, in \u001b[0;36m_CallAndUpdateTrace\u001b[0;34m(component, args, component_trace, treatment, target)\u001b[0m\n\u001b[1;32m    689\u001b[0m   component \u001b[39m=\u001b[39m loop\u001b[39m.\u001b[39mrun_until_complete(fn(\u001b[39m*\u001b[39mvarargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[1;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m   component \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49mvarargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    693\u001b[0m \u001b[39mif\u001b[39;00m treatment \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    694\u001b[0m   action \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mINSTANTIATED_CLASS\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epochs, num_gradients_accumulation, batch_size, gpu_id, lr, load_dir, decoder_model)\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[39m=\u001b[39m BertGPT()\n\u001b[1;32m     17\u001b[0m \u001b[39m# model.load_state_dict(torch.load(decoder_model))\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mDataParallel(model, device_ids \u001b[39m=\u001b[39;49m [\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m])\n\u001b[1;32m     20\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mload success\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:142\u001b[0m, in \u001b[0;36mDataParallel.__init__\u001b[0;34m(self, module, device_ids, output_device, dim)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device \u001b[39m=\u001b[39m _get_device_index(output_device, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(device_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 142\u001b[0m _check_balance(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    145\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_device_obj)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:23\u001b[0m, in \u001b[0;36m_check_balance\u001b[0;34m(device_ids)\u001b[0m\n\u001b[1;32m     17\u001b[0m imbalance_warn \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[39mThere is an imbalance between your GPUs. You may want to exclude GPU \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m which\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39mhas less than 75\u001b[39m\u001b[39m% o\u001b[39;00m\u001b[39mf the memory or cores of GPU \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. You can do so by setting\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mthe device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[39menvironment variable.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     22\u001b[0m device_ids \u001b[39m=\u001b[39m [_get_device_index(x, \u001b[39mTrue\u001b[39;00m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_ids]\n\u001b[0;32m---> 23\u001b[0m dev_props \u001b[39m=\u001b[39m _get_devices_properties(device_ids)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwarn_imbalance\u001b[39m(get_prop):\n\u001b[1;32m     26\u001b[0m     values \u001b[39m=\u001b[39m [get_prop(props) \u001b[39mfor\u001b[39;00m props \u001b[39min\u001b[39;00m dev_props]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py:491\u001b[0m, in \u001b[0;36m_get_devices_properties\u001b[0;34m(device_ids)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_devices_properties\u001b[39m(device_ids):\n\u001b[1;32m    490\u001b[0m     \u001b[39m# all device properties\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mreturn\u001b[39;00m [_get_device_attr(\u001b[39mlambda\u001b[39;00m m: m\u001b[39m.\u001b[39mget_device_properties(i)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m device_ids]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py:491\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_devices_properties\u001b[39m(device_ids):\n\u001b[1;32m    490\u001b[0m     \u001b[39m# all device properties\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mreturn\u001b[39;00m [_get_device_attr(\u001b[39mlambda\u001b[39;49;00m m: m\u001b[39m.\u001b[39;49mget_device_properties(i)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m device_ids]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py:474\u001b[0m, in \u001b[0;36m_get_device_attr\u001b[0;34m(get_member)\u001b[0m\n\u001b[1;32m    472\u001b[0m device_type \u001b[39m=\u001b[39m _get_available_device_type()\n\u001b[1;32m    473\u001b[0m \u001b[39mif\u001b[39;00m device_type \u001b[39mand\u001b[39;00m device_type\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 474\u001b[0m     \u001b[39mreturn\u001b[39;00m get_member(torch\u001b[39m.\u001b[39;49mcuda)\n\u001b[1;32m    475\u001b[0m \u001b[39m# add more available device types here\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py:491\u001b[0m, in \u001b[0;36m_get_devices_properties.<locals>.<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_devices_properties\u001b[39m(device_ids):\n\u001b[1;32m    490\u001b[0m     \u001b[39m# all device properties\u001b[39;00m\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mreturn\u001b[39;00m [_get_device_attr(\u001b[39mlambda\u001b[39;00m m: m\u001b[39m.\u001b[39;49mget_device_properties(i)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m device_ids]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:362\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    360\u001b[0m device \u001b[39m=\u001b[39m _get_device_index(device, optional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count():\n\u001b[0;32m--> 362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid device id\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    363\u001b[0m \u001b[39mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid device id"
     ]
    }
   ],
   "source": [
    "fire.Fire(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

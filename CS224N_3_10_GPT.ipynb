{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c3zfQWCnD0W",
        "outputId": "df472e35-b35b-47d8-d1cf-0d0e16a3b0c4"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBOal3VTnVBA",
        "outputId": "64964aee-6e5b-4ec7-eee1-f1ca15993efd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig, AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "PATH_NAME = \"./\"\n",
        "# %cd {PATH_NAME}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-exXSBTTkWz"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c39de0aba1a6466cb47780710f146310",
            "de0ce3a041fc44f8bb5213957861a91a",
            "27171d73a44444cda0db01d4f0b2b676",
            "c02c6cc988e2495c8be8b5807e0d2ceb",
            "88b225b31d7a4dd18d616a52ba751b37",
            "f0a0c9323335483ba9a49441b8ca2d96",
            "0f059e30fb24495c8925d99faabfbfa2",
            "ccaa1f467ae940e7b61b4b589753815b",
            "983bbb41a9b44a3d93dd76ebd83726ef",
            "8cc208b618404149ab0438110409e9e7",
            "1442415e405b48999724788891e58dd3",
            "c3455c075062402ea16ed62e00bc7162",
            "dc0a90bcd6a54a93afdf729f3dc2c3bf",
            "29df45d32bed4cb08cb56108c09062cc",
            "b43ff689e6584680a50e96491d6842e3",
            "b5e400ae7c024218965d3941a7dfb507",
            "2b079c6ab450421fb0a6f38cae4b7e93",
            "e846fc3cee5c4558bc5e60b4f0ae8865",
            "010758a706dd44b290018618b92b119b",
            "9c3d643290314e86ae300c86b25c0be7",
            "ce36459d41aa44e6859349bab27c6e0e",
            "414624725d25463589f1835fae69c8cf"
          ]
        },
        "id": "43F1PSern9_K",
        "outputId": "88c2ca06-3e7d-4d8a-b293-d622297108dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Sections of config\n",
        "\n",
        "# Defining key variables for dataLoader, Training\n",
        "MAX_LEN = 200\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "checkpoint = \"uer/gpt2-chinese-cluecorpussmall\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokenizer.model_max_len=512\n",
        "EPOCHS=3\n",
        "FILE_NAME = \"3-5-medical-bert.bin\"\n",
        "\n",
        "warmup_steps = 1e2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YE6v9S1rnmFw",
        "outputId": "05ae63e9-b3b9-4273-e979-37c9c9dcfcb4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialogue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ç—…äººï¼šè„±å‘ï¼Œæ¨åŒ»ç”Ÿä½ å¥½ï¼Œæˆ‘å¦ˆå¦ˆä¸‰ä¸ªæœˆå‰å¼€å§‹å‘ç°è„±å‘å‰å®³ï¼Œåˆšå¼€å§‹æ—¶æ‰å¤´å‘ï¼Œç°åœ¨æ˜¯è¿çœ‰æ¯›éƒ½å¼€å§‹æœ‰...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ç—…äººï¼šçº¤ç»´è…ºç˜¤ï¼Œè¿™æ®µæ—¶é—´æ¥æœˆç»å‰å°±ä¸€ç›´å·¦ä¹³æ¯”è¾ƒæ¶¨ç—›ã€‚åŒ»ç”Ÿï¼šå·²è¯Šã€‚</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ç—…äººï¼šä¾¿ç§˜ï¼Œä¾¿ç§˜çŒè‚ ï¼Œå››äº”å¤©ä¸å¤§ä¾¿ï¼Œå¤§ä¾¿ä¸å¹²ï¼Œå‘é»‘ã€‚åŒ»ç”Ÿï¼šä½ åº”è¯¥æ‰¾æ‰¾åŸå› ï¼Œåƒä¸­è¯è°ƒç†ã€‚</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ç—…äººï¼šæœ€åˆå¤§ä¸‰é˜³ç°åœ¨æ˜¯å°ä¸‰é˜³ï¼Œhbsag420.1hbsab2.1hbeag0hbsab0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ç—…äººï¼šç‰™ç—›ï¼Œä¸€ä¸ªå¤šæœˆäº†ï¼Œæœ€æ—©æ˜¯ä¸èˆ’æœï¼Œæœ€è¿‘éå¸¸ç—›ï¼Œç—›èµ·æ¥è¿ç€å·¦å¤ªé˜³ç©´ä¸€èµ·ç—›ï¼Œä½ç½®æ˜¯å·¦ä¸Šé‡Œé¢ç¬¬...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            dialogue\n",
              "0  ç—…äººï¼šè„±å‘ï¼Œæ¨åŒ»ç”Ÿä½ å¥½ï¼Œæˆ‘å¦ˆå¦ˆä¸‰ä¸ªæœˆå‰å¼€å§‹å‘ç°è„±å‘å‰å®³ï¼Œåˆšå¼€å§‹æ—¶æ‰å¤´å‘ï¼Œç°åœ¨æ˜¯è¿çœ‰æ¯›éƒ½å¼€å§‹æœ‰...\n",
              "1                   ç—…äººï¼šçº¤ç»´è…ºç˜¤ï¼Œè¿™æ®µæ—¶é—´æ¥æœˆç»å‰å°±ä¸€ç›´å·¦ä¹³æ¯”è¾ƒæ¶¨ç—›ã€‚åŒ»ç”Ÿï¼šå·²è¯Šã€‚\n",
              "2        ç—…äººï¼šä¾¿ç§˜ï¼Œä¾¿ç§˜çŒè‚ ï¼Œå››äº”å¤©ä¸å¤§ä¾¿ï¼Œå¤§ä¾¿ä¸å¹²ï¼Œå‘é»‘ã€‚åŒ»ç”Ÿï¼šä½ åº”è¯¥æ‰¾æ‰¾åŸå› ï¼Œåƒä¸­è¯è°ƒç†ã€‚\n",
              "3  ç—…äººï¼šæœ€åˆå¤§ä¸‰é˜³ç°åœ¨æ˜¯å°ä¸‰é˜³ï¼Œhbsag420.1hbsab2.1hbeag0hbsab0....\n",
              "4  ç—…äººï¼šç‰™ç—›ï¼Œä¸€ä¸ªå¤šæœˆäº†ï¼Œæœ€æ—©æ˜¯ä¸èˆ’æœï¼Œæœ€è¿‘éå¸¸ç—›ï¼Œç—›èµ·æ¥è¿ç€å·¦å¤ªé˜³ç©´ä¸€èµ·ç—›ï¼Œä½ç½®æ˜¯å·¦ä¸Šé‡Œé¢ç¬¬..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df = pd.read_csv(\"patient_data.csv\")\n",
        "# #df['list'] = df[df.columns[1:3]].values.tolist()\n",
        "# new_df = df[['id', 'doctor_faculty', 'description']].copy()\n",
        "# # new_df.head()\n",
        "\n",
        "# #map each department to an index \n",
        "# departments = new_df['doctor_faculty'].unique()\n",
        "# d2ind = {departments[i]:i for i in range(len(departments))}\n",
        "# ind2d = {i:departments[i] for i in range(len(departments))}\n",
        "\n",
        "# ground_truths = []\n",
        "# for i, row in new_df.iterrows():\n",
        "#   dept_name = row['doctor_faculty']\n",
        "#   dept_ind = d2ind[dept_name]\n",
        "#   one_hot = np.zeros(len(departments))\n",
        "#   one_hot[dept_ind] = 1\n",
        "#   ground_truths.append(one_hot)\n",
        "# new_df['one_hot'] = list(ground_truths)\n",
        "\n",
        "# new_df.drop(['id', 'doctor_faculty'], axis='columns', inplace=True)\n",
        "\n",
        "# new_df.head()\n",
        "f = open('Dataset/validate_data.json')\n",
        "data = json.load(f)\n",
        "f.close()\n",
        "conversation_list = []\n",
        "for row in data:\n",
        "    dialogue = ''\n",
        "    for d in row:\n",
        "        dialogue += d.strip()\n",
        "    conversation_list.append(dialogue)\n",
        "df = pd.DataFrame(conversation_list, columns=['dialogue'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ps0x5Rv7qjV6"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.dialogue = dataframe.dialogue\n",
        "        #self.targets = self.data.one_hot\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dialogue)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        dialogue = str(self.dialogue[index])\n",
        "        dialogue = \" \".join(dialogue.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            dialogue,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyH2BR0MttSW",
        "outputId": "06d804d3-bc17-4bd2-aa85-bf9645fbdc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FULL Dataset: (340749, 1)\n",
            "TRAIN Dataset: (272599, 1)\n",
            "TEST Dataset: (68150, 1)\n"
          ]
        }
      ],
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state=200)\n",
        "\n",
        "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "train_params = {'batch_size': BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 2\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 2\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "272599\n"
          ]
        }
      ],
      "source": [
        "## GPT2\n",
        "import re \n",
        "\n",
        "def build_text_files(data_json, dest_path):\n",
        "    f = open(dest_path, 'w')\n",
        "    data = ''\n",
        "    for texts in data_json.dialogue[:10000]:\n",
        "        summary = str(texts).strip()\n",
        "        summary = re.sub(r\"\\s\", \" \", summary)\n",
        "        data += summary + \"  \"\n",
        "    f.write(data)\n",
        "\n",
        "train_path = \"gpt_train_dataset.txt\"\n",
        "build_text_files(training_set, train_path)\n",
        "print(len(training_set))\n",
        "\n",
        "test_path = \"gpt_test_dataset.txt\"\n",
        "build_text_files(testing_set, test_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1915645 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextDataset\n",
        "train_path = \"gpt_train_dataset.txt\"\n",
        "training_loader = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "Creating features from dataset file at \n",
            "Saving features into cached file cached_lm_BertTokenizerFast_126_gpt_test_dataset.txt [took 0.023 s]\n"
          ]
        }
      ],
      "source": [
        "testing_loader = TextDataset(tokenizer=tokenizer, file_path=test_path, block_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py1eqCU6XuWD"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ub8AycYMvOxw"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "abd0d9f7449349afade0983623a15919",
            "93a773635d584376a226855d26f5c34f",
            "42686904338348d1b6c99df1a043d9b1",
            "cae14c5b4eea4e6e879fa3bcdbf1ace7",
            "ce479b486b694e588e89589ca50a1c76",
            "c15fa3c9f9444e01b33df5c9ebf6bd39",
            "3e119f24f2744689adff95cd376b8526",
            "2eed33c8ddd94c0894e5f3c55ae20fd2",
            "883961f320b04f29b48a7c7290f99949",
            "0500a6ba6f0f4fcc93eb17a26d592f44",
            "f2b9d97a90804cc7b53aefd53954f9fe"
          ]
        },
        "id": "qgVWeYk7wejw",
        "outputId": "370c3b11-95b2-40dd-f439-c9d318d0d907"
      },
      "outputs": [],
      "source": [
        "# from torch import nn\n",
        "# from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
        "# from transformers.modeling_outputs import TokenClassifierOutput\n",
        "\n",
        "# class CustomModel(torch.nn.Module):\n",
        "#   def __init__(self,checkpoint,num_labels,temperature=0.5, dropout_rate = 0.1): \n",
        "#     super(CustomModel,self).__init__() \n",
        "#     self.num_labels = num_labels \n",
        "#     self.projection_dim = 256\n",
        "#     self.temperature = temperature\n",
        "#     self.dropout_rate = dropout_rate\n",
        "\n",
        "#     #Load Model with given checkpoint and extract its body\n",
        "#     myConfig = AutoConfig.from_pretrained(checkpoint, output_attentions=True,output_hidden_states=True)\n",
        "#     myConfig.problem_type = \"multi_label_classification\"\n",
        "#     myConfig.temperature = self.temperature\n",
        "\n",
        "#     self.model = model = AutoModel.from_pretrained(checkpoint,config=myConfig)\n",
        "\n",
        "#     # Freezing paramaters\n",
        "#     # for param in self.model.parameters():\n",
        "#     #         param.requires_grad = False\n",
        "\n",
        "#     self.dropout = torch.nn.Dropout(self.dropout_rate) \n",
        "#     self.classifier = torch.nn.Linear(self.model.config.hidden_size,num_labels) # load and initialize weights\n",
        "#     self.criterion = torch.nn.CrossEntropyLoss() # define loss function\n",
        "\n",
        "#   def forward(self, input_ids=None, attention_mask=None,labels=None):\n",
        "#     #Extract outputs from the body\n",
        "\n",
        "#     outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "#     sequence_output = self.dropout(outputs[0])\n",
        "#     logits = self.classifier(sequence_output[:,0,:]) #predict the labels based on the projected output\n",
        "#     loss = self.criterion(logits, labels)\n",
        "#     GPTLoss = 1\n",
        "#     return loss +GPTLoss\n",
        "#     #seqeuence_output 8 200 768 for decoder \n",
        "#     #sequence_output.shape torch.Size([8, 200, 768]) sequence_output[:,0,:].shape torch.Size([8, 768]) sequence_output[:,0,:].view(-1,768).shape torch.Size([8, 768])\n",
        "#     return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,attentions=outputs.attentions)\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model=CustomModel(checkpoint=checkpoint,num_labels=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630,
          "referenced_widgets": [
            "d94d3e2b7de94fdb873491c1999b97f3",
            "7b9c01e5a6ef47cf8b01ac9d57a606a8",
            "69b3db0b5b024fa686eb2778e9952e91",
            "9b514e3c2fd6408682c79612c546a0ce",
            "1fe5fd5ce97e484889aabc0351a0adaf",
            "f82a2e9b2f7c4d6aa22567bf0e0ecb47",
            "9ad6869ec80244b4af3864be4b34dc94",
            "fbee80762a934d4e996d6ce4109021e9",
            "edddcdd9f8664b5a9c8c07bf4d65a94c",
            "b05a4936d4c4405699686a15ae251b4b",
            "1f83c7c572f34f4db88d5cc9aea59845",
            "207d85c18867464790914652ec8898b9",
            "2fb8ff0b37cd4e72828e517fe7e5aa6e",
            "453edfd477914950870c922fc8eda1cb",
            "9bdd0c666198476885c4db86137c985f",
            "3c164018ae5047df8fae43d98b8358f4",
            "0f2cb4e7755a456fb87e9b086d9cc7d8",
            "283e72a8c1654f47a5deadfcf88d1323",
            "28f8552491bd4457bf394218fa7935fd",
            "e059e9c25da14e03845ef4a5c18e5e36",
            "e01f666b338c4ef89de8bb26775670f7",
            "87ee08a68f6e40b5ad4d475aeec7952e",
            "155c7b9bd8614d51a98e2f2efda08883",
            "26091bbc12e0443493d23ea51184e4bc",
            "98cd14e0ed674deea5333a843c5edcd8",
            "65b23288926c452a9540a905d058aaa9",
            "dd149dbd4f9040d3a98bc8e85a5969e0",
            "8fb20ca436554a918daa9ae68ff8dfc6",
            "16f35a65c7e34983ada2868c3c316dfa",
            "a3b46428c1384a3b9839bb0b7dd7f891",
            "2e46192341e949efa90d01b73aa5862c",
            "3a59cb3b4a0a484cbbcae3dbcaa6a351",
            "87fe8d41fed74212a5ff952f0262ad35"
          ]
        },
        "id": "NuBBuih6xAFi",
        "outputId": "a80f0940-cb6c-41ba-a4dc-e53d80c76e3e"
      },
      "outputs": [],
      "source": [
        "# from tqdm.auto import tqdm\n",
        "# num_training_steps = EPOCHS * len(training_loader)\n",
        "# from datasets import load_metric\n",
        "# metric = load_metric(\"f1\")\n",
        "\n",
        "# def train(optimizer, model, training_loader, testing_loader, device, num_epochs, learning_rate = 0.1):\n",
        "#     best_accuracy = float('inf')\n",
        "\n",
        "#     print(\"Training Started with hyperparameters: batch_{BATCH}_lr_{LEARNING_RATE}_dropout_{DROPOUT}_temp_{TEMPERATURE}_weights.bin\".format(BATCH=training_loader.batch_size, LEARNING_RATE=learning_rate, DROPOUT=model.dropout_rate, TEMPERATURE=model.temperature))\n",
        "    \n",
        "#     for epoch in range(num_epochs):\n",
        "#         model.train()\n",
        "#         total_loss_current_epoch = 0\n",
        "#         for _,data in enumerate(training_loader, 0):\n",
        "#             ids = data['ids'].to(device, dtype = torch.long)\n",
        "#             mask = data['mask'].to(device, dtype = torch.long)\n",
        "#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "#             targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "#             #Calling the model\n",
        "#             outputs = model(ids, mask, targets)\n",
        "\n",
        "#             loss = outputs.loss\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             # lr_scheduler.step()\n",
        "#             optimizer.zero_grad()\n",
        "#             progress_bar_train.update(1)\n",
        "#             if _%5000==0:\n",
        "#                 print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            \n",
        "#             #Calculating total loss during this EPOCH\n",
        "#             total_loss_current_epoch += loss.item()\n",
        "\n",
        "#         outputs, targets = validation(model, testing_loader,device)\n",
        "#         outputs = np.array(outputs) >= 0.5\n",
        "#         accuracy = round(metrics.accuracy_score(targets, outputs),3)\n",
        "\n",
        "#         if accuracy < best_accuracy:\n",
        "#             best_accuracy = accuracy\n",
        "\n",
        "#             torch.save(model.classifier.state_dict(), \"{PATH_NAME}/{FILE_NAME}\".format(PATH_NAME=PATH_NAME, FILE_NAME = \"3_8_accuracy_{ACCURACY}_batch_{BATCH}_lr_{LEARNING_RATE}_dropout_{DROPOUT}_temp_{TEMPERATURE}_weights.bin\".format(ACCURACY=accuracy, BATCH=training_loader.batch_size, LEARNING_RATE=learning_rate, DROPOUT=model.dropout_rate, TEMPERATURE=model.temperature)))\n",
        "#             #torch.save(model.state_dict(), \"{PATH_NAME}/{FILE_NAME}\".format(PATH_NAME=PATH_NAME, FILE_NAME = FILE_NAME))\n",
        "#         print(f\"Epoch {epoch} - Validation Accuracy: {accuracy}\")\n",
        "\n",
        "#         epoch_loss = total_loss_current_epoch / len(training_loader)\n",
        "#         print(f\"Epoch {epoch} - Validation Loss: {epoch_loss}\")\n",
        "#         print(\"#\"*50)\n",
        "\n",
        "# progress_bar_train = tqdm(range(num_training_steps))\n",
        "# progress_bar_eval = tqdm(range(EPOCHS * len(testing_loader)))\n",
        "# optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# train(optimizer, model, training_loader, testing_loader, device, EPOCHS, LEARNING_RATE)\n",
        "\n",
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPT Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 15203\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1428\n",
            "  Number of trainable parameters = 102068736\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='1428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   3/1428 00:00 < 06:01, 3.94 it/s, Epoch 0.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./gpt2-gerchef/checkpoint-800\n",
            "Configuration saved in ./gpt2-gerchef/checkpoint-800/config.json\n",
            "Configuration saved in ./gpt2-gerchef/checkpoint-800/generation_config.json\n",
            "Configuration saved in ./gpt2-gerchef/checkpoint-800/config.json\n",
            "Configuration saved in ./gpt2-gerchef/checkpoint-800/generation_config.json\n",
            "Model weights saved in ./gpt2-gerchef/checkpoint-800/pytorch_model.bin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1428, training_loss=2.7532657227930235, metrics={'train_runtime': 377.9806, 'train_samples_per_second': 120.665, 'train_steps_per_second': 3.778, 'total_flos': 2979317071872000.0, 'train_loss': 2.7532657227930235, 'epoch': 3.0})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline, GPT2Config, AdamW, TrainingArguments, Trainer, AutoModelWithLMHead, DataCollatorForLanguageModeling\n",
        "epsilon = 1e-8\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(checkpoint).to(device)\n",
        "configuration = GPT2Config.from_pretrained(checkpoint, output_hidden_states=False)\n",
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# create a bunch of exaples of \"question:\" and \"doctor\" answer, and put it into one string. and use \"question: XXXX: doctor: \" to get the validation \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = LEARNING_RATE,\n",
        "                  eps = epsilon\n",
        "                )\n",
        "\n",
        "# text_generator = TextGenerationPipeline(model, tokenizer)\n",
        "# result = text_generator(\"è¿™æ˜¯å¾ˆä¹…ä¹‹å‰çš„äº‹æƒ…äº†\", max_length=100, do_sample=True)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-gerchef\", #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=3, # number of training epochs\n",
        "    per_device_train_batch_size=32, # batch size for training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    eval_steps = 400, # Number of update steps between two evaluations.\n",
        "    save_steps=800, # after # steps model is saved\n",
        "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
        "    )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=training_loader,\n",
        "    eval_dataset=testing_loader,\n",
        "    # prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./gpt2-gerchef\n",
            "Configuration saved in ./gpt2-gerchef/config.json\n",
            "Configuration saved in ./gpt2-gerchef/generation_config.json\n",
            "Model weights saved in ./gpt2-gerchef/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file ./gpt2-gerchef/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./gpt2-gerchef\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_past\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 320\n",
            "    }\n",
            "  },\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "loading configuration file ./gpt2-gerchef/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"./gpt2-gerchef\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_past\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 320\n",
            "    }\n",
            "  },\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "loading weights file ./gpt2-gerchef/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./gpt2-gerchef.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "loading configuration file ./gpt2-gerchef/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--uer--gpt2-chinese-cluecorpussmall/snapshots/7c87595de655dc7b0fbfaa545ae413a118063d0b/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"uer/gpt2-chinese-cluecorpussmall\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_past\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 320\n",
            "    }\n",
            "  },\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /home/ubuntu/.cache/huggingface/hub/models--uer--gpt2-chinese-cluecorpussmall/snapshots/7c87595de655dc7b0fbfaa545ae413a118063d0b/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /home/ubuntu/.cache/huggingface/hub/models--uer--gpt2-chinese-cluecorpussmall/snapshots/7c87595de655dc7b0fbfaa545ae413a118063d0b/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--uer--gpt2-chinese-cluecorpussmall/snapshots/7c87595de655dc7b0fbfaa545ae413a118063d0b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--uer--gpt2-chinese-cluecorpussmall/snapshots/7c87595de655dc7b0fbfaa545ae413a118063d0b/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"uer/gpt2-chinese-cluecorpussmall\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_past\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 320\n",
            "    }\n",
            "  },\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--uer--gpt2-chinese-cluecorpussmall/snapshots/7c87595de655dc7b0fbfaa545ae413a118063d0b/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"uer/gpt2-chinese-cluecorpussmall\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_past\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 320\n",
            "    }\n",
            "  },\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 320,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 320 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "chef = pipeline('text-generation',model='./gpt2-gerchef', tokenizer=checkpoint)\n",
        "result = chef(\"è¿™æ˜¯å¾ˆä¹…ä¹‹å‰çš„äº‹æƒ…äº†\")[0]['generated_text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"max_length\": 320,\n",
            "  \"transformers_version\": \"4.26.1\"\n",
            "}\n",
            "\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ç—…äººï¼šä¾¿ç§˜ï¼Œä¾¿ç§˜çŒè‚ ï¼Œå››äº”å¤©ä¸å¤§ä¾¿ï¼Œå¤§ä¾¿ä¸å¹²ï¼Œå‘é»‘ã€‚ åƒ å 3 - 4 å¤© ï¼Œ å‘ ç° å¤§ ä¾¿ ä¸ å¹² ï¼Œ è‚› é—¨ å¤„ ä¹Ÿ æœ‰ ã€‚ åŒ» ç”Ÿ ï¼š æ‚¨ å¥½ ï¼ æ‚¨ å¥½ ï¼ ç—… äºº ï¼š åŒ è…¿ å‘ å†·, å¤´ ç—› ã€‚ æ£€ æŸ¥ åŠ åŒ– éªŒ ï¼š ï¼š å³ è…¿ ä¸‹ æ–¹ ä¸‰ ä¸ª å° é’ˆ çœ¼ ä½ ç½® ã€ ã€ å³ è…¿ è† å…³ èŠ‚ é™„ è¿‘ ä¸ èƒ½ åŠ¨ ã€‚ åŒ» ç”Ÿ ï¼š ä½  å¥½ ï¼ ç—… äºº ï¼š é¢ˆ æ¤ ç—… ï¼Œ ç”· ï¼Œ 36 å² ï¼Œ é¢ˆ æ¤ ç—… ï¼Œ æ‚£ æ—¶ å‘ ç—… ä¸‰ å¹´ ï¼Œ å·¦\n"
          ]
        }
      ],
      "source": [
        "result = chef(\"ç—…äººï¼šä¾¿ç§˜ï¼Œä¾¿ç§˜çŒè‚ ï¼Œå››äº”å¤©ä¸å¤§ä¾¿ï¼Œå¤§ä¾¿ä¸å¹²ï¼Œå‘é»‘ã€‚\")[0]['generated_text']\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 100/102225 [01:21<23:15:03,  1.22it/s]\n",
            "  0%|          | 0/25557 [01:21<?, ?it/s]\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "\n",
            "\u001b[A\n",
            "\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  2.2694733142852783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  34,075. Loss: 2.0098118782043457.   Elapsed: 0:00:13.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: joseph ç—… ï¼ˆ tumblr strangension ï¼‰ ï¼Œ åœ¨ æŸ äº› æƒ… å†µ ä¸‹ ï¼Œ å®ƒ ä¼š å¯¼ è‡´ ç™Œ ç—‡ ï¼ˆ ä¹Ÿ å¯ ä»¥ è¯´ ï¼š æ¶ æ€§ è‚¿ ç˜¤ ï¼‰ ï¼Œ å¹¶ ä¸” å¾ˆ å¯ èƒ½ æ˜¯ æ¶ æ€§ æ·‹ å·´ ç˜¤ ã€‚ ç—… äºº åœ¨ ä¸ åŒ æƒ… å†µ ä¸‹ ï¼Œ æœ‰ å¯ èƒ½ å‡º ç° ä¸ åŒ çš„ å æœ ï¼Œ ä¼š è¿› ä¸€ æ­¥ å¢ åŠ  æ‚£ è€… ä¸ ç»„ ç»‡ ä¹‹ é—´ çš„ çŸ› ç›¾ ã€‚ strategy science for the parents who used to drug as a district or phenomenon like in parallax to spiritual treatment in the pale of the cancer. drug in triborating of a large cell treatment to restricted. treatment is appreciatively successful about all the other medicine of pare to deploy discussion of the clini\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  34,075. Loss: 1.9783436059951782.   Elapsed: 0:00:27.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: äº‰ ç—… ç—‡ åŠ åŒ» å­¦ ç ” ç©¶ ä¸­ ï¼Œ ç›® å‰ äºº å£ å¯† åº¦ è¿˜ æ²¡ æœ‰ å‘ ç”Ÿ æ˜ æ˜¾ çš„ å˜ åŒ– ï¼Œ ä½† ç›¸ å…³ çš„ äºº ç¾¤ æ•° é‡ å¢ åŠ  ï¼Œ äºº å‡ ä½“ æ£€ äºº æ•° çš„ æŒ ç»­ å¢ é•¿ å’Œ åŸº å±‚ åŒ» ç–— èµ„ æº çš„ å®Œ å–„ å·² ä¸º ä¸´ åºŠ æ²» ç–— æ ä¾› äº† æœ‰ åˆ© æ¡ ä»¶ ã€‚ äºº å£ åŸº ç¡€ æ•° é‡ çš„ å¢ åŠ  ã€ åŒ» ç–— æŠ€ æœ¯ èƒ½ åŠ› çš„ å¢ åŠ  ã€ åŸº å±‚ åŒ» ç–— å« ç”Ÿ æœº æ„ èƒ½ å¤Ÿ ä¸º ç¾¤ ä¼— æ ä¾› æ›´ å¥½ çš„ åŒ» ç–— æœ åŠ¡ ï¼Œ ä» è€Œ æ é«˜ äº† åŸº å±‚ åŒ» ç–— å« ç”Ÿ æœ åŠ¡ çš„ è´¨ é‡ ã€‚ 2. åŒ» ç”Ÿ åœ¨ æ—¥ å¸¸ åŒ» ç–— ä¿ å¥ å·¥ ä½œ ä¸­ ï¼Œ åº” ä» åŒ» ç”Ÿ ã€ åŒ» ç”Ÿ ä½œ ä¸º ä¸­ ä»‹ ï¼Œ å åŠ© ä»– ä»¬ æ ä¾› æœ åŠ¡ ï¼Œ ä¸º æ‚£ è€… æ ä¾› ä¸“ ä¸š çš„ åŒ» ç–— æœ åŠ¡ ï¼Œ åŒ» ç”Ÿ åœ¨ æ—¥ å¸¸ ç”Ÿ æ´» çš„ ä¿ å¥ å·¥ ä½œ ä¸­ æ˜¯ æœ‰ ç€ é‡\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [1,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [2,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  34,075. Loss: 1.3759506940841675.   Elapsed: 0:00:42.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m progress_bar_train \u001b[39m=\u001b[39m tqdm(\u001b[39mrange\u001b[39m(num_training_steps))\n\u001b[1;32m     97\u001b[0m progress_bar_eval \u001b[39m=\u001b[39m tqdm(\u001b[39mrange\u001b[39m(EPOCHS \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(testing_loader)))\n\u001b[0;32m---> 99\u001b[0m GPTtrain(optimizer, model, training_loader, testing_loader, device, lr_scheduler, EPOCHS, LEARNING_RATE)\n",
            "Cell \u001b[0;32mIn[10], line 52\u001b[0m, in \u001b[0;36mGPTtrain\u001b[0;34m(optimizer, model, training_loader, testing_loader, device, lr_scheduler, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m  Batch \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m  of  \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m. Loss: \u001b[39m\u001b[39m{:>5,}\u001b[39;00m\u001b[39m.   Elapsed: \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(_, \u001b[39mlen\u001b[39m(training_loader), batch_loss, elapsed))\n\u001b[1;32m     50\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 52\u001b[0m sample_outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     53\u001b[0m                         bos_token_id\u001b[39m=\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandint(\u001b[39m1\u001b[39;49m,\u001b[39m30000\u001b[39;49m),\n\u001b[1;32m     54\u001b[0m                         do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,   \n\u001b[1;32m     55\u001b[0m                         top_k\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, \n\u001b[1;32m     56\u001b[0m                         max_length \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m,\n\u001b[1;32m     57\u001b[0m                         top_p\u001b[39m=\u001b[39;49m\u001b[39m0.95\u001b[39;49m, \n\u001b[1;32m     58\u001b[0m                         num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     59\u001b[0m                         \u001b[39m# token_type_ids=token_type_ids,\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m                         \u001b[39m# attention_mask=mask\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m                     )\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m i, sample_output \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sample_outputs):\n\u001b[1;32m     63\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i, tokenizer\u001b[39m.\u001b[39mdecode(sample_output, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)))\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1437\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1430\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1431\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1432\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1433\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1434\u001b[0m     )\n\u001b[1;32m   1436\u001b[0m     \u001b[39m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m   1438\u001b[0m         input_ids,\n\u001b[1;32m   1439\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1440\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[1;32m   1441\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1442\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1443\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1444\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1445\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1446\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1447\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1448\u001b[0m     )\n\u001b[1;32m   1450\u001b[0m \u001b[39melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1451\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m generation_config\u001b[39m.\u001b[39mnum_beams:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:2443\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2440\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2442\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2443\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2444\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2445\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2446\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2447\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2448\u001b[0m )\n\u001b[1;32m   2450\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2451\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1043\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1043\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m   1044\u001b[0m     input_ids,\n\u001b[1;32m   1045\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1046\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1047\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1048\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1049\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1050\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1051\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1052\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   1053\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1054\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1055\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1056\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1057\u001b[0m )\n\u001b[1;32m   1058\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1060\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:887\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    877\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    878\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    879\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    884\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    885\u001b[0m     )\n\u001b[1;32m    886\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 887\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    888\u001b[0m         hidden_states,\n\u001b[1;32m    889\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    890\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    891\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    892\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    893\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    894\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    895\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    899\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:388\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    386\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    387\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 388\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    389\u001b[0m     hidden_states,\n\u001b[1;32m    390\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    391\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    392\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    393\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    394\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    395\u001b[0m )\n\u001b[1;32m    396\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    397\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:329\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m     attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    331\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_heads(attn_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[1;32m    332\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(attn_output)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:216\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights \u001b[39m*\u001b[39m head_mask\n\u001b[0;32m--> 216\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attn_weights, value)\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "total_steps = len(training_loader) * EPOCHS\n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import random \n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
        "\n",
        "def GPTtrain(optimizer, model, training_loader, testing_loader, device, lr_scheduler, num_epochs, learning_rate = 0.1):\n",
        "    best_accuracy = float('inf')\n",
        "    t0 = time.time()\n",
        "    # print(\"Training Started with hyperparameters: batch_{BATCH}_lr_{LEARNING_RATE}_dropout_{DROPOUT}_temp_{TEMPERATURE}_weights.bin\".format(BATCH=training_loader.batch_size, LEARNING_RATE=learning_rate, DROPOUT=model.dropout_rate, TEMPERATURE=model.temperature))\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss_current_epoch = 0\n",
        "        for _,data in enumerate(training_loader, 0):\n",
        "            model.zero_grad() \n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            # targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            #Calling the model\n",
        "            # print(model)\n",
        "            # print(\"ids[0]\", ids[7])\n",
        "            # print(\"ids.shape\", ids.shape, \"targets.shape\", targets.shape, \"mask.shape\", mask.shape, \"token_type_ids.shape\", token_type_ids.shape)\n",
        "            \n",
        "            outputs = model(ids, attention_mask=mask, labels=ids, token_type_ids=token_type_ids)\n",
        "\n",
        "            loss = outputs[0]\n",
        "            batch_loss = loss.item()\n",
        "            total_loss_current_epoch += batch_loss\n",
        "\n",
        "\n",
        "            # Get sample every x batches.\n",
        "            if _ % 100 == 0 and not _ == 0:\n",
        "\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(_, len(training_loader), batch_loss, elapsed))\n",
        "\n",
        "                model.eval()\n",
        "\n",
        "                sample_outputs = model.generate(\n",
        "                                        bos_token_id=random.randint(1,30000),\n",
        "                                        do_sample=True,   \n",
        "                                        top_k=50, \n",
        "                                        max_length = 200,\n",
        "                                        top_p=0.95, \n",
        "                                        num_return_sequences=1,\n",
        "                                        # token_type_ids=token_type_ids,\n",
        "                                        # attention_mask=mask\n",
        "                                    )\n",
        "                for i, sample_output in enumerate(sample_outputs):\n",
        "                    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "                \n",
        "                model.train()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "            progress_bar_train.update(1)\n",
        "            if _%5000==0:\n",
        "                print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            \n",
        "            #Calculating total loss during this EPOCH\n",
        "            total_loss_current_epoch += loss.item()\n",
        "\n",
        "        # outputs, targets = validation(model, testing_loader,device)\n",
        "        # outputs = np.array(outputs) >= 0.5\n",
        "        # accuracy = round(metrics.accuracy_score(targets, outputs),3)\n",
        "\n",
        "        # if accuracy < best_accuracy:\n",
        "        #     best_accuracy = accuracy\n",
        "\n",
        "        # torch.save(model.classifier.state_dict(), \"{PATH_NAME}/{FILE_NAME}\".format(PATH_NAME=PATH_NAME, FILE_NAME = \"3_8_accuracy_{ACCURACY}_batch_{BATCH}_lr_{LEARNING_RATE}_dropout_{DROPOUT}_temp_{TEMPERATURE}_weights.bin\".format(ACCURACY=accuracy, BATCH=training_loader.batch_size, LEARNING_RATE=learning_rate, DROPOUT=model.dropout_rate, TEMPERATURE=model.temperature)))\n",
        "            #torch.save(model.state_dict(), \"{PATH_NAME}/{FILE_NAME}\".format(PATH_NAME=PATH_NAME, FILE_NAME = FILE_NAME))\n",
        "        # print(f\"Epoch {epoch} - Validation Accuracy: {accuracy}\")\n",
        "\n",
        "        epoch_loss = total_loss_current_epoch / len(training_loader)\n",
        "        print(f\"Epoch {epoch} - Validation Loss: {epoch_loss}\")\n",
        "        print(\"#\"*50)\n",
        "num_training_steps = EPOCHS * len(training_loader)\n",
        "progress_bar_train = tqdm(range(num_training_steps))\n",
        "progress_bar_eval = tqdm(range(EPOCHS * len(testing_loader)))\n",
        "\n",
        "GPTtrain(optimizer, model, training_loader, testing_loader, device, lr_scheduler, EPOCHS, LEARNING_RATE)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## T5 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration\n",
        "\n",
        "# load tokenizer and model \n",
        "pretrained_model = \"IDEA-CCNL/Randeng-T5-784M-MultiTask-Chinese\"\n",
        "\n",
        "special_tokens = [\"<extra_id_{}>\".format(i) for i in range(100)]\n",
        "tokenizer = T5Tokenizer.from_pretrained(\n",
        "    pretrained_model,\n",
        "    do_lower_case=True,\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    additional_special_tokens=special_tokens,\n",
        ")\n",
        "config = T5Config.from_pretrained(pretrained_model)\n",
        "model = T5ForConditionalGeneration.from_pretrained(pretrained_model, config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenize\n",
        "text = \"ç—…æƒ…è¯Šæ–­ä»»åŠ¡ï¼š æŒ‡ç”²ä¸Šçªèµ·çš„æ¨ªçº¹ç—…æƒ…æè¿°ï¼š ä¸Šå‘¨å‘ç°æ‹‡æŒ‡æŒ‡ç”²ä¸Šçªèµ·ä¸€é“æ¨ªçº¹ï¼ä¸ç–¼ä¸ç—’ï¼Œçªèµ·æ¥çš„æ¨ªçº¹ï¼å¸Œæœ›è·å¾—çš„å¸®åŠ©ï¼š åœ¨å®¶ç”¨ä»€ä¹ˆè¯ï¼æ‚£ç—…å¤šä¹…ï¼š ä¸€æœˆå†…è¿‡æ•å²ï¼š æ— ï¼ˆ2020-03-27å¡«å†™ï¼‰æ—¢å¾€ç—…å²ï¼š ã€æ‰‹æœ¯ã€‘ï¼š17å¹´åšè¿‡è‚ ç™Œæ‰‹æœ¯ï¼ï¼ˆ2020-03-27å¡«å†™ï¼‰æ—¢å¾€ç—…å²ï¼š æ— ï¼ˆ2020-03-23 å‘Šè¯‰æˆ‘è¿™ä¸ªç—…äººåº”è¯¥çœ‹ä»€ä¹ˆåŒ»ç”Ÿ\"\n",
        "encode_dict = tokenizer(text, max_length=512, padding='max_length',truncation=True)\n",
        "\n",
        "inputs = {\n",
        "  \"input_ids\": torch.tensor([encode_dict['input_ids']]).long(),\n",
        "  \"attention_mask\": torch.tensor([encode_dict['attention_mask']]).long(),\n",
        "  }\n",
        "\n",
        "# generate answer\n",
        "logits = model.generate(\n",
        "  input_ids = inputs['input_ids'],\n",
        "  max_length=100, \n",
        "  do_sample= True\n",
        "  # early_stopping=True,\n",
        "  )\n",
        "\n",
        "logits=logits[:,3:]\n",
        "predict_label = [tokenizer.decode(i,skip_special_tokens=True) for i in logits]\n",
        "print(predict_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"shibing624/prompt-t5-base-chinese\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"shibing624/prompt-t5-base-chinese\")\n",
        "def batch_generate(input_texts, max_length=64):\n",
        "    features = tokenizer(input_texts, return_tensors='pt')\n",
        "    outputs = model.generate(input_ids=features['input_ids'],\n",
        "                             attention_mask=features['attention_mask'],\n",
        "                             max_length=max_length)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "r = batch_generate([\"æ¨ç†ï¼šæŒ‡ç”²ä¸Šçªèµ·çš„æ¨ªçº¹ç—…æƒ…æè¿°ï¼š ä¸Šå‘¨å‘ç°æ‹‡æŒ‡æŒ‡ç”²ä¸Šçªèµ·ä¸€é“æ¨ªçº¹ï¼ä¸ç–¼ä¸ç—’ï¼Œçªèµ·æ¥çš„æ¨ªçº¹ï¼å¸Œæœ›è·å¾—çš„å¸®åŠ©ï¼š åœ¨å®¶ç”¨ä»€ä¹ˆè¯ï¼æ‚£ç—…å¤šä¹…ï¼š ä¸€æœˆå†…è¿‡æ•å²ï¼š æ— ï¼ˆ2020-03-27å¡«å†™ï¼‰æ—¢å¾€ç—…å²ï¼š ã€æ‰‹æœ¯ã€‘ï¼š17å¹´åšè¿‡è‚ ç™Œæ‰‹æœ¯ï¼\"])\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import T5Tokenizer,MT5ForConditionalGeneration\n",
        "\n",
        "pretrain_path = 'IDEA-CCNL/Randeng-T5-784M-QA-Chinese'\n",
        "tokenizer=T5Tokenizer.from_pretrained(pretrain_path)\n",
        "model=MT5ForConditionalGeneration.from_pretrained(pretrain_path)\n",
        "\n",
        "sample={\"context\":\"åœ¨æŸæ—,èƒ¡æ ¼è¯ºæ´¾æ•™å¾’åˆ›å»ºäº†ä¸¤ä¸ªæ–°çš„ç¤¾åŒº:å¤šç½—è¥¿æ©æ–¯å¡”ç‰¹å’Œå¼—é‡Œå¾·é‡Œå¸Œæ–¯å¡”ç‰¹ã€‚åˆ°1700å¹´,è¿™ä¸ªåŸå¸‚äº”åˆ†ä¹‹ä¸€çš„äººå£è®²æ³•è¯­ã€‚æŸæ—èƒ¡æ ¼è¯ºæ´¾åœ¨ä»–ä»¬çš„æ•™å ‚æœåŠ¡ä¸­ä¿ç•™äº†å°†è¿‘ä¸€ä¸ªä¸–çºªçš„æ³•è¯­ã€‚ä»–ä»¬æœ€ç»ˆå†³å®šæ”¹ç”¨å¾·è¯­,ä»¥æŠ—è®®1806-1807å¹´æ‹¿ç ´ä»‘å é¢†æ™®é²å£«ã€‚ä»–ä»¬çš„è®¸å¤šåä»£éƒ½æœ‰æ˜¾èµ«çš„åœ°ä½ã€‚æˆç«‹äº†å‡ ä¸ªæ•™ä¼š,å¦‚å¼—é›·å¾·é‡Œå¤(ä¸¹éº¦)ã€æŸæ—ã€æ–¯å¾·å“¥å°”æ‘©ã€æ±‰å ¡ã€æ³•å…°å…‹ç¦ã€èµ«å°”è¾›åŸºå’ŒåŸƒå§†ç™»çš„æ•™ä¼šã€‚\",\"question\":\"é™¤äº†å¤šç½—è¥¿æ©æ–¯å¡”ç‰¹,æŸæ—è¿˜æœ‰å“ªä¸ªæ–°çš„ç¤¾åŒº?\",\"idx\":1}\n",
        "plain_text='question:'+sample['question']+'knowledge:'+sample['context'][:500]\n",
        "\n",
        "res_prefix=tokenizer.encode('answer',add_special_token=False)\n",
        "res_prefix.append(tokenizer.convert_tokens_to_ids('<extra_id_0>'))\n",
        "EOS_TOKEN_ID = tokenizer.convert_tokens_to_ids('<extra_id_0>')\n",
        "res_prefix.append(EOS_TOKEN_ID)\n",
        "l_rp=len(res_prefix)\n",
        "\n",
        "tokenized=tokenizer.encode(plain_text,add_special_tokens=False,truncation=True,max_length=500)\n",
        "tokenized+=res_prefix\n",
        "batch=[tokenized]*2\n",
        "input_ids=torch.tensor(np.array(batch),dtype=torch.long)\n",
        "\n",
        "# Generate answer\n",
        "pred_ids = model.generate(input_ids=input_ids,max_new_token=500,do_sample=True,top_p=0.9)\n",
        "pred_tokens=tokenizer.batch_decode(pred_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "res=pred_tokens.replace('<extra_id_0>','').replace('æœ‰ç­”æ¡ˆ:','')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtdeLgs-aibC"
      },
      "source": [
        "## Validation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WO0czM06Aw8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def validation( model, testing_loader, device, model_weights_path = None):\n",
        "\n",
        "    if model_weights_path:\n",
        "      state_dict = torch.load(PATH_NAME+model_weights_path)\n",
        "      model.load_state_dict(state_dict)\n",
        "      # model.classifier.load_state_dict(torch.load(PATH_NAME+'classification_head_weights.bin'))\n",
        "\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, targets)\n",
        "            \n",
        "            sigmoids = torch.sigmoid(outputs.logits).cpu().detach().numpy().tolist()\n",
        "            idx = np.argmax(sigmoids, axis=-1)\n",
        "            sigmoids = np.zeros( (len(sigmoids), len(sigmoids[1])) )\n",
        "            sigmoids[ np.arange(len(sigmoids)), idx] = 1\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(sigmoids)\n",
        "    return fin_outputs, fin_targets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {'dropout': [0.1, 0.2],\n",
        "              'learning_rate': [0.0001,0.001, 0.01],\n",
        "              'batch_size': [32, 64],\n",
        "              'temperature': [0.9, 0.7]}\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.optim as optim\n",
        "\n",
        "for batch_size in param_grid['batch_size']:\n",
        "    train_params = {'batch_size': batch_size,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 2\n",
        "                }\n",
        "\n",
        "    test_params = {'batch_size': batch_size,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 2\n",
        "                }\n",
        "\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "    for learning_rate in param_grid['learning_rate']:\n",
        "        for dropout_rate in param_grid['dropout']:\n",
        "            for temperature in param_grid['temperature']:\n",
        "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "                model=CustomModel(checkpoint=checkpoint, num_labels=10, temperature=temperature, dropout_rate=dropout_rate).to(device)\n",
        "                optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "                train(optimizer, model, training_loader, testing_loader, device, EPOCHS, LEARNING_RATE)\n",
        "\n",
        "                \n",
        "\n",
        "                \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKJEOsNGVSna"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Define additional metrics\n",
        "def precision(outputs, targets):\n",
        "    return metrics.precision_score(targets, outputs, average = 'weighted')\n",
        "\n",
        "def recall(outputs, targets):\n",
        "    return metrics.recall_score(targets, outputs, average = 'weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBOzi05OCniw"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1):\n",
        "    outputs, targets = validation(FILE_NAME)\n",
        "    print('outputs', outputs)\n",
        "    print('targets', targets)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    precision_score = precision(outputs, targets)\n",
        "    recall_score = recall(outputs, targets)\n",
        "      \n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "    print(f\"Precision Score = {precision_score}\")\n",
        "    print(f\"Recall Score = {recall_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnLTmrsUlUGA"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"{PATH_NAME}/roberta-base-additional-classification-layer-bert-medical.bin\".format(PATH_NAME=PATH_NAME))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "010758a706dd44b290018618b92b119b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0500a6ba6f0f4fcc93eb17a26d592f44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f059e30fb24495c8925d99faabfbfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f2cb4e7755a456fb87e9b086d9cc7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1442415e405b48999724788891e58dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "155c7b9bd8614d51a98e2f2efda08883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26091bbc12e0443493d23ea51184e4bc",
              "IPY_MODEL_98cd14e0ed674deea5333a843c5edcd8",
              "IPY_MODEL_65b23288926c452a9540a905d058aaa9"
            ],
            "layout": "IPY_MODEL_dd149dbd4f9040d3a98bc8e85a5969e0"
          }
        },
        "16f35a65c7e34983ada2868c3c316dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f83c7c572f34f4db88d5cc9aea59845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fe5fd5ce97e484889aabc0351a0adaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207d85c18867464790914652ec8898b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fb8ff0b37cd4e72828e517fe7e5aa6e",
              "IPY_MODEL_453edfd477914950870c922fc8eda1cb",
              "IPY_MODEL_9bdd0c666198476885c4db86137c985f"
            ],
            "layout": "IPY_MODEL_3c164018ae5047df8fae43d98b8358f4"
          }
        },
        "26091bbc12e0443493d23ea51184e4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb20ca436554a918daa9ae68ff8dfc6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_16f35a65c7e34983ada2868c3c316dfa",
            "value": "  0%"
          }
        },
        "27171d73a44444cda0db01d4f0b2b676": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccaa1f467ae940e7b61b4b589753815b",
            "max": 730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_983bbb41a9b44a3d93dd76ebd83726ef",
            "value": 730
          }
        },
        "283e72a8c1654f47a5deadfcf88d1323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f8552491bd4457bf394218fa7935fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29df45d32bed4cb08cb56108c09062cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010758a706dd44b290018618b92b119b",
            "max": 109540,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c3d643290314e86ae300c86b25c0be7",
            "value": 109540
          }
        },
        "2b079c6ab450421fb0a6f38cae4b7e93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e46192341e949efa90d01b73aa5862c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eed33c8ddd94c0894e5f3c55ae20fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb8ff0b37cd4e72828e517fe7e5aa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f2cb4e7755a456fb87e9b086d9cc7d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_283e72a8c1654f47a5deadfcf88d1323",
            "value": "  1%"
          }
        },
        "3a59cb3b4a0a484cbbcae3dbcaa6a351": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c164018ae5047df8fae43d98b8358f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e119f24f2744689adff95cd376b8526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "414624725d25463589f1835fae69c8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42686904338348d1b6c99df1a043d9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eed33c8ddd94c0894e5f3c55ae20fd2",
            "max": 411621366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_883961f320b04f29b48a7c7290f99949",
            "value": 411621366
          }
        },
        "453edfd477914950870c922fc8eda1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f8552491bd4457bf394218fa7935fd",
            "max": 12965,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e059e9c25da14e03845ef4a5c18e5e36",
            "value": 152
          }
        },
        "65b23288926c452a9540a905d058aaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a59cb3b4a0a484cbbcae3dbcaa6a351",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87fe8d41fed74212a5ff952f0262ad35",
            "value": " 0/6485 [00:00&lt;?, ?it/s]"
          }
        },
        "69b3db0b5b024fa686eb2778e9952e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbee80762a934d4e996d6ce4109021e9",
            "max": 2318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edddcdd9f8664b5a9c8c07bf4d65a94c",
            "value": 2318
          }
        },
        "7b9c01e5a6ef47cf8b01ac9d57a606a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f82a2e9b2f7c4d6aa22567bf0e0ecb47",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ad6869ec80244b4af3864be4b34dc94",
            "value": "Downloading builder script: "
          }
        },
        "87ee08a68f6e40b5ad4d475aeec7952e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87fe8d41fed74212a5ff952f0262ad35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "883961f320b04f29b48a7c7290f99949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88b225b31d7a4dd18d616a52ba751b37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cc208b618404149ab0438110409e9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb20ca436554a918daa9ae68ff8dfc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a773635d584376a226855d26f5c34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15fa3c9f9444e01b33df5c9ebf6bd39",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3e119f24f2744689adff95cd376b8526",
            "value": "Downloading (â€¦)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "983bbb41a9b44a3d93dd76ebd83726ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98cd14e0ed674deea5333a843c5edcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3b46428c1384a3b9839bb0b7dd7f891",
            "max": 6485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e46192341e949efa90d01b73aa5862c",
            "value": 0
          }
        },
        "9ad6869ec80244b4af3864be4b34dc94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b514e3c2fd6408682c79612c546a0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05a4936d4c4405699686a15ae251b4b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1f83c7c572f34f4db88d5cc9aea59845",
            "value": " 6.50k/? [00:00&lt;00:00, 393kB/s]"
          }
        },
        "9bdd0c666198476885c4db86137c985f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e01f666b338c4ef89de8bb26775670f7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87ee08a68f6e40b5ad4d475aeec7952e",
            "value": " 152/12965 [00:29&lt;17:18, 12.34it/s]"
          }
        },
        "9c3d643290314e86ae300c86b25c0be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3b46428c1384a3b9839bb0b7dd7f891": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd0d9f7449349afade0983623a15919": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93a773635d584376a226855d26f5c34f",
              "IPY_MODEL_42686904338348d1b6c99df1a043d9b1",
              "IPY_MODEL_cae14c5b4eea4e6e879fa3bcdbf1ace7"
            ],
            "layout": "IPY_MODEL_ce479b486b694e588e89589ca50a1c76"
          }
        },
        "b05a4936d4c4405699686a15ae251b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b43ff689e6584680a50e96491d6842e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce36459d41aa44e6859349bab27c6e0e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_414624725d25463589f1835fae69c8cf",
            "value": " 110k/110k [00:00&lt;00:00, 641kB/s]"
          }
        },
        "b5e400ae7c024218965d3941a7dfb507": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02c6cc988e2495c8be8b5807e0d2ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cc208b618404149ab0438110409e9e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1442415e405b48999724788891e58dd3",
            "value": " 730/730 [00:00&lt;00:00, 29.3kB/s]"
          }
        },
        "c15fa3c9f9444e01b33df5c9ebf6bd39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3455c075062402ea16ed62e00bc7162": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc0a90bcd6a54a93afdf729f3dc2c3bf",
              "IPY_MODEL_29df45d32bed4cb08cb56108c09062cc",
              "IPY_MODEL_b43ff689e6584680a50e96491d6842e3"
            ],
            "layout": "IPY_MODEL_b5e400ae7c024218965d3941a7dfb507"
          }
        },
        "c39de0aba1a6466cb47780710f146310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de0ce3a041fc44f8bb5213957861a91a",
              "IPY_MODEL_27171d73a44444cda0db01d4f0b2b676",
              "IPY_MODEL_c02c6cc988e2495c8be8b5807e0d2ceb"
            ],
            "layout": "IPY_MODEL_88b225b31d7a4dd18d616a52ba751b37"
          }
        },
        "cae14c5b4eea4e6e879fa3bcdbf1ace7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0500a6ba6f0f4fcc93eb17a26d592f44",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f2b9d97a90804cc7b53aefd53954f9fe",
            "value": " 412M/412M [00:10&lt;00:00, 42.8MB/s]"
          }
        },
        "ccaa1f467ae940e7b61b4b589753815b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce36459d41aa44e6859349bab27c6e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce479b486b694e588e89589ca50a1c76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94d3e2b7de94fdb873491c1999b97f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9c01e5a6ef47cf8b01ac9d57a606a8",
              "IPY_MODEL_69b3db0b5b024fa686eb2778e9952e91",
              "IPY_MODEL_9b514e3c2fd6408682c79612c546a0ce"
            ],
            "layout": "IPY_MODEL_1fe5fd5ce97e484889aabc0351a0adaf"
          }
        },
        "dc0a90bcd6a54a93afdf729f3dc2c3bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b079c6ab450421fb0a6f38cae4b7e93",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e846fc3cee5c4558bc5e60b4f0ae8865",
            "value": "Downloading (â€¦)solve/main/vocab.txt: 100%"
          }
        },
        "dd149dbd4f9040d3a98bc8e85a5969e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0ce3a041fc44f8bb5213957861a91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a0c9323335483ba9a49441b8ca2d96",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f059e30fb24495c8925d99faabfbfa2",
            "value": "Downloading (â€¦)lve/main/config.json: 100%"
          }
        },
        "e01f666b338c4ef89de8bb26775670f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e059e9c25da14e03845ef4a5c18e5e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e846fc3cee5c4558bc5e60b4f0ae8865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edddcdd9f8664b5a9c8c07bf4d65a94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0a0c9323335483ba9a49441b8ca2d96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b9d97a90804cc7b53aefd53954f9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f82a2e9b2f7c4d6aa22567bf0e0ecb47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbee80762a934d4e996d6ce4109021e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
